{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7d2f3-e83b-494c-87c0-414c3df653df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import bisect\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from decimal import Decimal\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from aind_data_schema.core.session import (\n",
    "    DetectorConfig,\n",
    "    FieldOfView,\n",
    "    LaserConfig,\n",
    "    Modality,\n",
    "    Session,\n",
    "    Stream, \n",
    "    TriggerType,\n",
    ")\n",
    "from aind_data_schema.models.stimulus import (\n",
    "    PhotoStimulation,\n",
    "    PhotoStimulationGroup,\n",
    "    StimulusEpoch,\n",
    ")\n",
    "from aind_data_schema.models.units import PowerUnit, SizeUnit, TimeUnit\n",
    "from pydantic import Field\n",
    "from pydantic_settings import BaseSettings\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc0356-ff17-49ed-af4d-9e6cf1f3c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For information that can't be parsed from the tif files, it needs to be a field here.\n",
    "# I'm not sure whether things can be set as default values. Please update it if the\n",
    "# defaults I'm using don't make send. Just remove the defaults.\n",
    "\n",
    "class JobSettings(BaseSettings):\n",
    "    \"\"\"Data that needs to be input by user. Can be pulled from env vars with\n",
    "    BERGAMO prefix or set explicitly.\"\"\"\n",
    "\n",
    "    input_source: Path = Field(\n",
    "        ..., description=\"Directory of files that need to be parsed.\"\n",
    "    )\n",
    "    output_directory: Optional[Path] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"Directory where to save the json file to. If None, then json\"\n",
    "            \" contents will be returned in the Response message.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    experimenter_full_name: List[str]\n",
    "    subject_id: str\n",
    "\n",
    "    # TODO: Look into whether defaults can be set for these fields\n",
    "    mouse_platform_name: str\n",
    "    active_mouse_platform: bool\n",
    "\n",
    "    # Data that might change but can have default values\n",
    "    session_type: str = \"BCI\"\n",
    "    iacuc_protocol: str = \"2115\"\n",
    "    rig_id: str = \"Bergamo photostim.\"\n",
    "    camera_names: List[str] = [\"Side Camera\"]\n",
    "    laser_a_name: str = \"Laser A\"\n",
    "    laser_a_wavelength: int = 920\n",
    "    laser_a_wavelength_unit: SizeUnit = SizeUnit.NM\n",
    "    detector_a_name: str = \"PMT A\"\n",
    "    detector_a_exposure_time: Decimal = Decimal('0.1')\n",
    "    detector_a_trigger_type: TriggerType = TriggerType.INTERNAL\n",
    "    stimulus_name: str = \"PhotoStimulation\"\n",
    "    fov_0_index: int = 0\n",
    "    fov_0_imaging_depth: int = 150\n",
    "    fov_0_targeted_structure: str = \"M1\"\n",
    "    fov_0_coordinate_ml: Decimal = Decimal('1.5')\n",
    "    fov_0_coordinate_ap: float = Decimal('1.5')\n",
    "    fov_0_reference: str = \"Bregma\"\n",
    "    fov_0_magnification: str = \"16x\"\n",
    "    stream_modalities: List[Modality.ONE_OF] = [Modality.POPHYS]\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Config to set env var prefix to BERGAMO\"\"\"\n",
    "\n",
    "        env_prefix = \"BERGAMO_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d40d74-f21c-4a04-9ae1-8e6788825a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class makes it easier to flag which tif files are which expected type\n",
    "\n",
    "class TifFileGroup(str, Enum):\n",
    "    BEHAVIOR = \"behavior\"\n",
    "    PHOTOSTIM = \"photostim\"\n",
    "    SPONTANEOUS = \"spontaneous\"\n",
    "    STACK = \"stack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710fc1f0-0c6b-4ec8-b9b0-6685364f9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will hold the metadata information pulled from the tif files with minimal parsing.\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RawImageInfo:\n",
    "    \"\"\"Raw metadata from a tif file\"\"\"\n",
    "\n",
    "    reader_metadata_header: dict\n",
    "    reader_metadata_json: dict\n",
    "    # The reader descriptions for the last tif file\n",
    "    reader_descriptions: List[dict]\n",
    "    # Looks like [620, 800, 800]\n",
    "    # [num_of_frames, pixel_width, pixel_height]?\n",
    "    reader_shape: List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1786871-b110-47ed-9009-12ca56650be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is a container to hold only the tif file metadata information needed to build the \n",
    "# Session.json file\n",
    "# More stuff can be added if necessary.\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ParsedMetadataInfo:\n",
    "    \"\"\"Tif file metadata that's needed downstream\"\"\"\n",
    "\n",
    "    tif_file_group: TifFileGroup\n",
    "    number_of_tif_files: int  # This should correspond to the number of trials\n",
    "    h_photostim: dict\n",
    "    h_roi_manager: dict\n",
    "    h_beams: dict\n",
    "    h_fast_z: dict\n",
    "    imaging_roi_group: dict\n",
    "    photostim_roi_groups: List[dict]\n",
    "    reader_description_last: dict\n",
    "    reader_shape: List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec32c9b-d0a7-4ee2-888c-2db7f623216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions will be used to translate the tif file information into information\n",
    "# needed to build the Session.json file. They need to be re-usable and preferrably modular.\n",
    "# I can bundle them into a class to ensure they all process the same job_settings class.\n",
    "# I'll keep them independent for purposes of sharing a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59383563-ef15-492b-9a6f-d81578c7ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tif_file_locations(job_settings: JobSettings) -> Dict[str, List[Path]]:\n",
    "    \"\"\"Scans the input source directory and returns a dictionary of file\n",
    "    groups in an ordered list. For example, if the directory had\n",
    "    [neuron2_00001.tif, neuron2_00002.tif, stackPost_00001.tif,\n",
    "    stackPost_00002.tif, stackPost_00003.tif], then it will return\n",
    "    { \"neuron2\": [neuron2_00001.tif, neuron2_00002.tif],\n",
    "     \"stackPost\":\n",
    "       [stackPost_00001.tif, stackPost_00002.tif, stackPost_00003.tif]\n",
    "    }\n",
    "    \"\"\"\n",
    "    compiled_regex = re.compile(r\"^(.*)_.*?(\\d+).tif+$\")\n",
    "    tif_file_map = {}\n",
    "    for root, dirs, files in os.walk(job_settings.input_source):\n",
    "        for name in files:\n",
    "            matched = re.match(compiled_regex, name)\n",
    "            if matched:\n",
    "                groups = matched.groups()\n",
    "                file_stem = groups[0]\n",
    "                # tif_number = groups[1]\n",
    "                tif_filepath = Path(os.path.join(root, name))\n",
    "                if tif_file_map.get(file_stem) is None:\n",
    "                    tif_file_map[file_stem] = [tif_filepath]\n",
    "                else:\n",
    "                    bisect.insort(tif_file_map[file_stem], tif_filepath)\n",
    "\n",
    "        # Only scan the top level files\n",
    "        break\n",
    "    return tif_file_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9544c61-3b17-4dd2-82ae-c3ecd3005778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_dict_to_nested(flat: dict, key_delim: str = \".\") -> dict:\n",
    "    \"\"\"\n",
    "    Utility method to convert a flat dictionary into a nested dictionary.\n",
    "    Modified from https://stackoverflow.com/a/50607551\n",
    "    Parameters\n",
    "    ----------\n",
    "    flat : dict\n",
    "      Example {\"a.b.c\": 1, \"a.b.d\": 2, \"e.f\": 3}\n",
    "    key_delim : str\n",
    "      Delimiter on dictionary keys. Default is '.'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "      A nested dictionary like {\"a\": {\"b\": {\"c\":1, \"d\":2}, \"e\": {\"f\":3}}\n",
    "    \"\"\"\n",
    "\n",
    "    def __nest_dict_rec(k, v, out) -> None:\n",
    "        \"\"\"Simple recursive method being called.\"\"\"\n",
    "        k, *rest = k.split(key_delim, 1)\n",
    "        if rest:\n",
    "            __nest_dict_rec(rest[0], v, out.setdefault(k, {}))\n",
    "        else:\n",
    "            out[k] = v\n",
    "\n",
    "    result = {}\n",
    "    for flat_key, flat_val in flat.items():\n",
    "        __nest_dict_rec(flat_key, flat_val, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9913a-1ed2-494e-9292-5be8dd9b4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This methods parses a single file into RawImageInfo dataclass\n",
    "def extract_raw_info_from_file(file_path: Path) -> RawImageInfo:\n",
    "    with ScanImageTiffReader(str(file_path)) as reader:\n",
    "        reader_metadata = reader.metadata()\n",
    "        reader_shape = reader.shape()\n",
    "        reader_descriptions = [\n",
    "            dict(\n",
    "                [\n",
    "                    (s.split(\" = \", 1)[0], s.split(\" = \", 1)[1])\n",
    "                    for s in reader.description(i).strip().split(\"\\n\")\n",
    "                ]\n",
    "            )\n",
    "            for i in range(0, len(reader))\n",
    "        ]\n",
    "\n",
    "    metadata_first_part = reader_metadata.split(\"\\n\\n\")[0]\n",
    "    flat_metadata_header_dict = dict(\n",
    "        [\n",
    "            (s.split(\" = \", 1)[0], s.split(\" = \", 1)[1])\n",
    "            for s in metadata_first_part.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "    metadata_dict = flat_dict_to_nested(flat_metadata_header_dict)\n",
    "    reader_metadata_json = json.loads(reader_metadata.split(\"\\n\\n\")[1])\n",
    "    # Move SI dictionary up one level\n",
    "    if \"SI\" in metadata_dict.keys():\n",
    "        si_contents = metadata_dict.pop(\"SI\")\n",
    "        metadata_dict.update(si_contents)\n",
    "    return RawImageInfo(\n",
    "        reader_shape=reader_shape,\n",
    "        reader_metadata_header=metadata_dict,\n",
    "        reader_metadata_json=reader_metadata_json,\n",
    "        reader_descriptions=reader_descriptions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1f5a1-8bb9-48ee-b2c6-8176b4b0979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method maps a RawImageInfo dataclass into a TifFileGroup type\n",
    "\n",
    "def map_raw_image_info_to_tif_file_group(\n",
    "    raw_image_info: RawImageInfo,\n",
    ") -> TifFileGroup:\n",
    "    header = raw_image_info.reader_metadata_header\n",
    "    if header.get(\"hPhotostim\", {}).get(\"status\") in [\n",
    "        \"'Running'\",\n",
    "        \"Running\",\n",
    "    ]:\n",
    "        return TifFileGroup.PHOTOSTIM\n",
    "    elif (\n",
    "        header.get(\"hIntegrationRoiManager\", {}).get(\"enable\") == \"true\"\n",
    "        and header.get(\"hIntegrationRoiManager\", {}).get(\n",
    "            \"outputChannelsEnabled\"\n",
    "        )\n",
    "        == \"true\"\n",
    "        and header.get(\"extTrigEnable\", {}) == \"1\"\n",
    "    ):\n",
    "        return TifFileGroup.BEHAVIOR\n",
    "    elif header.get(\"hStackManager\", {}).get(\"enable\") == \"true\":\n",
    "        return TifFileGroup.STACK\n",
    "    else:\n",
    "        return TifFileGroup.SPONTANEOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53acd763-4d10-4c77-8f38-9311093b53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method transforms a RawImageInfo class into an intermediate ParsedMetadatInfo class.\n",
    "# It should be easier to deal with the more focused ParsedMetadataInfo class than the RawImageInfo.\n",
    "# If other fields from the RawImageInfo are needed downstream, we can update things here.\n",
    "\n",
    "def parse_raw_metadata(\n",
    "    raw_image_info: RawImageInfo, number_of_files: int\n",
    ") -> ParsedMetadataInfo:\n",
    "    h_roi_manager = raw_image_info.reader_metadata_header.get(\n",
    "        \"hRoiManager\", {}\n",
    "    )\n",
    "    h_beams = raw_image_info.reader_metadata_header.get(\"hBeams\", {})\n",
    "    h_fast_z = raw_image_info.reader_metadata_header.get(\"hFastZ\", {})\n",
    "    h_photostim = raw_image_info.reader_metadata_header.get(\n",
    "        \"hPhotostim\", {}\n",
    "    )\n",
    "    roi_groups = raw_image_info.reader_metadata_json.get(\"RoiGroups\", {})\n",
    "    imaging_roi_group = roi_groups.get(\"imagingRoiGroup\", {})\n",
    "    photostim_roi_groups = roi_groups.get(\"photostimRoiGroups\", [])\n",
    "\n",
    "    reader_description_last = raw_image_info.reader_descriptions[-1]\n",
    "\n",
    "    tif_file_group = map_raw_image_info_to_tif_file_group(\n",
    "        raw_image_info=raw_image_info\n",
    "    )\n",
    "\n",
    "    return ParsedMetadataInfo(\n",
    "        tif_file_group=tif_file_group,\n",
    "        number_of_tif_files=number_of_files,\n",
    "        h_photostim=h_photostim,\n",
    "        h_roi_manager=h_roi_manager,\n",
    "        h_beams=h_beams,\n",
    "        h_fast_z=h_fast_z,\n",
    "        imaging_roi_group=imaging_roi_group,\n",
    "        photostim_roi_groups=photostim_roi_groups,\n",
    "        reader_description_last=reader_description_last,\n",
    "        reader_shape=raw_image_info.reader_shape,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb010aa4-2529-441f-8b65-115d22365eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through tif file locations and transforms them into a dictionary of ParsedMetadataInfo\n",
    "\n",
    "def extract_parsed_metadata_info_from_files(\n",
    "    tif_file_locations: Dict[str, List[Path]]\n",
    ") -> Dict[Tuple[str, TifFileGroup], ParsedMetadataInfo]:\n",
    "    parsed_map = {}\n",
    "    for file_stem, files in tif_file_locations.items():\n",
    "        number_of_files = len(files)\n",
    "        last_file = files[-1]\n",
    "        raw_info = extract_raw_info_from_file(last_file)\n",
    "        parsed_info = parse_raw_metadata(\n",
    "            raw_image_info=raw_info, number_of_files=number_of_files\n",
    "        )\n",
    "        parsed_map[(file_stem, parsed_info.tif_file_group)] = parsed_info\n",
    "    return parsed_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26d2d1-2c03-40dc-ae59-d1fa42899d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous methods are to extract the information from the tif files into something more manageable.\n",
    "# The following methods do the work of mapping that information into aind-data-schema classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29b95b-4cdc-4c99-aaab-41c31ced9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method maps a parsed_info_group pulled from ParsedMetadataInfo.photostim_roi_groups\n",
    "# where the ParsedMetadataInfo is labeled as photostim. The output is an \n",
    "# aind_data_schema.models.stimulus.PhotoStimulationGroup object.\n",
    "\n",
    "def map_parsed_info_group_to_photo_stim_group(\n",
    "    parsed_info_group: dict, list_index: int, number_of_trials: int\n",
    ") -> PhotoStimulationGroup:\n",
    "    number_of_neurons = int(\n",
    "        np.array(\n",
    "            parsed_info_group[\"rois\"][1][\"scanfields\"][\"slmPattern\"]\n",
    "        ).shape[0]\n",
    "    )\n",
    "    stimulation_laser_power = Decimal(\n",
    "        str(parsed_info_group[\"rois\"][1][\"scanfields\"][\"powers\"])\n",
    "    )\n",
    "    number_spirals = int(\n",
    "        parsed_info_group[\"rois\"][1][\"scanfields\"][\"repetitions\"]\n",
    "    )\n",
    "    spiral_duration = Decimal(\n",
    "        str(parsed_info_group[\"rois\"][1][\"scanfields\"][\"duration\"])\n",
    "    )\n",
    "    inter_spiral_interval = Decimal(\n",
    "        str(parsed_info_group[\"rois\"][2][\"scanfields\"][\"duration\"])\n",
    "    )\n",
    "    return PhotoStimulationGroup(\n",
    "        group_index=list_index,\n",
    "        number_of_neurons=number_of_neurons,\n",
    "        stimulation_laser_power=stimulation_laser_power,\n",
    "        stimulation_laser_power_unit=PowerUnit.PERCENT,\n",
    "        number_trials=number_of_trials,\n",
    "        number_spirals=number_spirals,\n",
    "        spiral_duration=spiral_duration,\n",
    "        inter_spiral_interval=inter_spiral_interval,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773b85e-5b6e-433b-8b93-eb50ab9675c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method maps a ParsedMetadataInfo object that was labeled as photostim into\n",
    "# an aind_data_schema.models.stimulus.StimulusEpoch object\n",
    "\n",
    "def map_photo_stim_info_to_stimulus_epoch(\n",
    "    job_settings: JobSettings,\n",
    "    photo_stim_info: ParsedMetadataInfo\n",
    ") -> StimulusEpoch:\n",
    "\n",
    "    # Number of trials should equal the number of tif files in the\n",
    "    # photo_stim group?\n",
    "    number_of_trials = photo_stim_info.number_of_tif_files\n",
    "    sequence_stimulus = json.loads(\n",
    "        photo_stim_info.h_photostim.get(\n",
    "            \"sequenceSelectedStimuli\", \"[]\"\n",
    "        ).replace(\" \", \",\")\n",
    "    )\n",
    "    number_of_groups = max(sequence_stimulus)\n",
    "    # In theory, the number of groups should\n",
    "    # match len(photostim_info.photostim_roi_groups)\n",
    "    mapped_photostimulation_groups = [\n",
    "        map_parsed_info_group_to_photo_stim_group(\n",
    "            parsed_info_group=e[1],\n",
    "            list_index=e[0],\n",
    "            number_of_trials=number_of_trials,\n",
    "        )\n",
    "        for e in enumerate(photo_stim_info.photostim_roi_groups)\n",
    "    ]\n",
    "    # Look into this?\n",
    "    inter_trial_interval = 1 / Decimal(\n",
    "        photo_stim_info.h_roi_manager[\"scanFrameRate\"]\n",
    "    ) * photo_stim_info.reader_shape[0]\n",
    "    stimulus_start_time = datetime.strptime(\n",
    "        photo_stim_info.reader_description_last[\"epoch\"],\n",
    "        \"[%Y %m %d %H %M %S.%f]\",\n",
    "    )\n",
    "    elapsed_time = float(\n",
    "        photo_stim_info.reader_description_last[\"frameTimestamps_sec\"]\n",
    "    )\n",
    "    stimulus_end_time = stimulus_start_time + timedelta(\n",
    "        seconds=elapsed_time\n",
    "    )\n",
    "    photo_stimulation = PhotoStimulation(\n",
    "        stimulus_name=job_settings.stimulus_name,\n",
    "        number_groups=number_of_groups,\n",
    "        groups=mapped_photostimulation_groups,\n",
    "        inter_trial_interval=inter_trial_interval,\n",
    "    )\n",
    "\n",
    "    return StimulusEpoch(\n",
    "        stimulus_start_time=stimulus_start_time,\n",
    "        stimulus_end_time=stimulus_end_time,\n",
    "        stimulus=photo_stimulation,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ba1b8-e5d1-41d9-a788-a473c786b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method maps a ParsedMetadataInfo object that was labeled as photostim into\n",
    "# an aind_data_schema.core.session.Stream object\n",
    "\n",
    "def map_photo_stim_info_to_streams(job_settings: JobSettings, photo_stim_info: ParsedMetadataInfo) -> Stream:\n",
    "    stream_start_time = datetime.strptime(\n",
    "        photo_stim_info.reader_description_last[\"epoch\"],\n",
    "        \"[%Y %m %d %H %M %S.%f]\",\n",
    "    )\n",
    "    elapsed_time = float(\n",
    "        photo_stim_info.reader_description_last[\"frameTimestamps_sec\"]\n",
    "    )\n",
    "    stream_end_time = stream_start_time + timedelta(\n",
    "        seconds=elapsed_time\n",
    "    )\n",
    "    laser_config = LaserConfig(\n",
    "        name=job_settings.laser_a_name,  # Must match rig json\n",
    "        wavelength =job_settings.laser_a_wavelength,\n",
    "        excitation_power=Decimal(\n",
    "            photo_stim_info.h_beams['powers'][1:-1].split()[0]\n",
    "        ),\n",
    "        excitation_power_unit = PowerUnit.PERCENT,\n",
    "    )\n",
    "    detector_config = DetectorConfig(\n",
    "        name=job_settings.detector_a_name,\n",
    "        exposure_time=job_settings.detector_a_exposure_time,\n",
    "        exposure_time_unit=TimeUnit.S,\n",
    "        trigger_type=job_settings.detector_a_trigger_type\n",
    "    )\n",
    "    ophys_fov = FieldOfView(\n",
    "        index=0,\n",
    "        imaging_depth=job_settings.fov_0_imaging_depth,\n",
    "        targeted_structure=job_settings.fov_0_targeted_structure,\n",
    "        fov_coordinate_ml=job_settings.fov_0_coordinate_ml,\n",
    "        fov_coordinate_ap=job_settings.fov_0_coordinate_ap,\n",
    "        fov_reference=job_settings.fov_0_reference,\n",
    "        fov_width=int(\n",
    "            photo_stim_info.h_roi_manager['pixelsPerLine']),\n",
    "        fov_height=int(\n",
    "            photo_stim_info.h_roi_manager['linesPerFrame']),\n",
    "        magnification=job_settings.fov_0_magnification,\n",
    "        fov_scale_factor=Decimal(\n",
    "            photo_stim_info.h_roi_manager['scanZoomFactor']\n",
    "        ),\n",
    "        frame_rate=Decimal(\n",
    "            photo_stim_info.h_roi_manager['scanFrameRate']),\n",
    "    )\n",
    "    camera_names = job_settings.camera_names\n",
    "    return Stream(\n",
    "        stream_start_time=stream_start_time,\n",
    "        stream_end_time=stream_end_time,\n",
    "        camera_names=camera_names,\n",
    "        light_sources=[\n",
    "            laser_config\n",
    "        ],\n",
    "        detectors=[detector_config],\n",
    "        ophys_fovs=[ophys_fov],\n",
    "        mouse_platform_name=job_settings.mouse_platform_name,\n",
    "        active_mouse_platform=job_settings.active_mouse_platform,\n",
    "        stream_modalities=job_settings.stream_modalities,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97ee62-01f3-4582-a6fc-75c0fae2ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will probably need additional mapping functions for the other TifFileTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af2565-ce24-4fc9-a26b-8c12fc8c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main method that transforms the parsed information into\n",
    "# an aind_data_schema.core.session.Session object\n",
    "\n",
    "def transform(job_settings: JobSettings, parsed_data: Dict[Tuple[str, TifFileGroup], ParsedMetadataInfo]) -> Session:\n",
    "\n",
    "    photo_stim_file_info = [\n",
    "        (k, v)\n",
    "        for k, v in parsed_data.items()\n",
    "        if k[1] == TifFileGroup.PHOTOSTIM\n",
    "    ]\n",
    "    # There should only be one photo_stim group? We can add an assertion\n",
    "    photo_stim_info = photo_stim_file_info[0][1]\n",
    "    stimulus_epoch = map_photo_stim_info_to_stimulus_epoch(job_settings=job_settings, photo_stim_info=photo_stim_info)\n",
    "    stream = map_photo_stim_info_to_streams(job_settings=job_settings, photo_stim_info=photo_stim_info)\n",
    "\n",
    "    return Session(\n",
    "        experimenter_full_name=job_settings.experimenter_full_name,\n",
    "        session_start_time=stream.stream_start_time,\n",
    "        session_end_time=stream.stream_end_time,\n",
    "        session_type=job_settings.session_type,\n",
    "        iacuc_protocol=job_settings.iacuc_protocol,\n",
    "        rig_id=job_settings.rig_id,\n",
    "        subject_id=job_settings.subject_id,\n",
    "        animal_weight_prior=None,\n",
    "        animal_weight_post=None,\n",
    "        data_streams=[stream],\n",
    "        stimulus_epochs=[stimulus_epoch],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1ecce-0c6e-44ad-8bcf-4eef591a4b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cdeb38-f1d3-424a-b5bb-a5d0231014bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is an example of how to run this in a jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fa5d5-eafb-4637-ae9e-b23f540e66ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04146e3-d4c1-4e78-80c8-dc1d6a76c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file_path = Path(\"//allen/aind/scratch/svc_aind_upload/test_data_sets/bci/061022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a983bd-e981-4b30-bb4b-c78db01b531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_settings = JobSettings(\n",
    "    input_source=tif_file_path,\n",
    "    experimenter_full_name=[\"John Apple\"],\n",
    "    subject_id=\"061022\",\n",
    "    mouse_platform_name=\"Platform A\",\n",
    "    active_mouse_platform=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6046f3-1e9d-4761-803b-69a1fd729717",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file_locations = get_tif_file_locations(job_settings=job_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b4e59-8972-4afc-ae4c-02b5907c0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a3527-f412-4675-9cb3-d0866192394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_metadata = extract_parsed_metadata_info_from_files(tif_file_locations=tif_file_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99bab5-c6d6-4cc7-b461-20a69df0d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995b529-4700-456d-ab88-fbc81df0acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_stim_file_info = [\n",
    "    (k, v)\n",
    "    for k, v in parsed_metadata.items()\n",
    "    if k[1] == TifFileGroup.PHOTOSTIM\n",
    "]\n",
    "# There should only be one photo_stim group? We can add an assertion\n",
    "photo_stim_info = photo_stim_file_info[0][1]\n",
    "stimulus_epoch = map_photo_stim_info_to_stimulus_epoch(job_settings=job_settings, photo_stim_info=photo_stim_info)\n",
    "# stream = map_photo_stim_info_to_streams(job_settings=job_settings, photo_stim_info=photo_stim_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2955c-7543-4522-9710-c1318d7cb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "session=transform(job_settings=job_settings, parsed_data=parsed_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79278510-8e1b-4bd0-b9d2-aba784b122c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540cce1-e095-4b71-9737-d8585ec74c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
