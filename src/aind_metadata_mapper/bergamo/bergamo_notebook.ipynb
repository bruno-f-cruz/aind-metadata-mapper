{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "cc3d5540-7c2c-4614-a2b1-901e385c771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import bisect\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from zoneinfo import ZoneInfo\n",
    "from decimal import Decimal\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from aind_data_schema.core.session import (\n",
    "    DetectorConfig,\n",
    "    FieldOfView,\n",
    "    LaserConfig,\n",
    "    Modality,\n",
    "    Session,\n",
    "    Stream, \n",
    "    TriggerType,\n",
    "    RewardDeliveryConfig,\n",
    "    RewardSolution,\n",
    "    RewardSpoutConfig,\n",
    "    SpoutSide,\n",
    "    LaserConfig,\n",
    "    Stack,\n",
    "    StackChannel,\n",
    "    StimulusEpoch,\n",
    "    StimulusModality\n",
    ")\n",
    "from aind_data_schema.imaging.tile import Channel\n",
    "from aind_data_schema.models.devices import Calibration, Software\n",
    "from aind_data_schema.models.stimulus import (\n",
    "    PhotoStimulation,\n",
    "    PhotoStimulationGroup,#    StimulusEpoch,\n",
    ")\n",
    "from aind_data_schema.models.coordinates import Translation3dTransform, Rotation3dTransform, RelativePosition, Axis, AxisName\n",
    "from aind_data_schema.models.units import PowerUnit, SizeUnit, TimeUnit\n",
    "from pydantic import Field\n",
    "from pydantic_settings import BaseSettings\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "06d09a8d-5532-4d5e-b581-87eded5ddf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For information that can't be parsed from the tif files, it needs to be a field here.\n",
    "# I'm not sure whether things can be set as default values. Please update it if the\n",
    "# defaults I'm using don't make send. Just remove the defaults.\n",
    "# \n",
    "class JobSettings(BaseSettings):\n",
    "    \"\"\"Data that needs to be input by user. Can be pulled from env vars with\n",
    "    BERGAMO prefix or set explicitly.\"\"\"\n",
    "\n",
    "    input_source: Path = Field(\n",
    "        ..., description=\"Directory of files that need to be parsed.\"\n",
    "    )\n",
    "    output_directory: Optional[Path] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"Directory where to save the json file to. If None, then json\"\n",
    "            \" contents will be returned in the Response message.\"\n",
    "        ),\n",
    "    )\n",
    "    # mandatory fields:\n",
    "    experimenter_full_name: List[str]\n",
    "    subject_id: str\n",
    "    imaging_laser_wavelength: int # user defined\n",
    "    fov_imaging_depth: int\n",
    "    fov_targeted_structure: str\n",
    "    notes: str\n",
    "    \n",
    "    \n",
    "    # fields with default values\n",
    "    mouse_platform_name: str = 'tube' # should match rig json\n",
    "    active_mouse_platform : bool = False\n",
    "    session_type: str = \"BCI\"\n",
    "    iacuc_protocol: str = \"2109\"\n",
    "    rig_id: str = \"Bergamo photostim rig\" # should match rig json\n",
    "    behavior_camera_names: List[str] = [\"Side Face Camera\", \"Bottom Face Camera\"] # should match rig json\n",
    "    imaging_laser_name: str = \"Chameleon tunable pulsing laser\" # should match rig json\n",
    "    \n",
    "    photostim_laser_name: str = \"Monaco 1040nm pulsing laser\" # should match rig json\n",
    "    photostim_laser_wavelength  :int = 1040\n",
    "    fov_coordinate_ml: Decimal = Decimal('1.5')\n",
    "    fov_coordinate_ap: float = Decimal('1.5')\n",
    "    fov_reference: str = \"Bregma\"\n",
    "    \n",
    "    starting_lickport_position : list[float] = [0, -6, 0] # in mm from face of the mouse\n",
    "    behavior_task_name : str = 'single neuron BCI conditioning'\n",
    "    timezone: ZoneInfo = ZoneInfo('US/Pacific')\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Config to set env var prefix to BERGAMO\"\"\"\n",
    "\n",
    "        env_prefix = \"BERGAMO_\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "09e5b50f-76fd-4dc7-aa04-5c4640163d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class makes it easier to flag which tif files are which expected type\n",
    "\n",
    "class TifFileGroup(str, Enum):\n",
    "    BEHAVIOR = \"behavior\"\n",
    "    PHOTOSTIM = \"photostim\"\n",
    "    SPONTANEOUS = \"spontaneous\"\n",
    "    STACK = \"stack\"\n",
    "    \n",
    "# This class will hold the metadata information pulled from the tif files with minimal parsing.\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RawImageInfo:\n",
    "    \"\"\"Raw metadata from a tif file\"\"\"\n",
    "\n",
    "    reader_metadata_header: dict\n",
    "    reader_metadata_json: dict\n",
    "    # The reader descriptions for the last tif file\n",
    "    reader_descriptions: List[dict]\n",
    "    # Looks like [620, 800, 800]\n",
    "    # [num_of_frames, pixel_width, pixel_height]?\n",
    "    reader_shape: List[int]\n",
    "    \n",
    "# This class is a container to hold only the tif file metadata information needed to build the \n",
    "# Session.json file\n",
    "# More stuff can be added if necessary.\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ParsedMetadataInfo:\n",
    "    \"\"\"Tif file metadata that's needed downstream\"\"\"\n",
    "\n",
    "    tif_file_group: TifFileGroup\n",
    "    number_of_tif_files: int  # This should correspond to the number of trials\n",
    "    h_photostim: dict\n",
    "    h_roi_manager: dict\n",
    "    h_beams: dict\n",
    "    h_fast_z: dict\n",
    "    imaging_roi_group: dict\n",
    "    photostim_roi_groups: List[dict]\n",
    "    reader_description_last: dict\n",
    "    reader_shape: List[int]\n",
    "    \n",
    "# The following functions will be used to translate the tif file information into information\n",
    "# needed to build the Session.json file. They need to be re-usable and preferrably modular.\n",
    "# I can bundle them into a class to ensure they all process the same job_settings class.\n",
    "# I'll keep them independent for purposes of sharing a jupyter notebook.\n",
    "\n",
    "def get_tif_file_locations(job_settings: JobSettings) -> Dict[str, List[Path]]:\n",
    "    \"\"\"Scans the input source directory and returns a dictionary of file\n",
    "    groups in an ordered list. For example, if the directory had\n",
    "    [neuron2_00001.tif, neuron2_00002.tif, stackPost_00001.tif,\n",
    "    stackPost_00002.tif, stackPost_00003.tif], then it will return\n",
    "    { \"neuron2\": [neuron2_00001.tif, neuron2_00002.tif],\n",
    "     \"stackPost\":\n",
    "       [stackPost_00001.tif, stackPost_00002.tif, stackPost_00003.tif]\n",
    "    }\n",
    "    \"\"\"\n",
    "    compiled_regex = re.compile(r\"^(.*)_.*?(\\d+).tif+$\")\n",
    "    tif_file_map = {}\n",
    "    for root, dirs, files in os.walk(job_settings.input_source):\n",
    "        for name in files:\n",
    "            matched = re.match(compiled_regex, name)\n",
    "            if matched:\n",
    "                groups = matched.groups()\n",
    "                file_stem = groups[0]\n",
    "                # tif_number = groups[1]\n",
    "                tif_filepath = Path(os.path.join(root, name))\n",
    "                if tif_file_map.get(file_stem) is None:\n",
    "                    tif_file_map[file_stem] = [tif_filepath]\n",
    "                else:\n",
    "                    bisect.insort(tif_file_map[file_stem], tif_filepath)\n",
    "\n",
    "        # Only scan the top level files\n",
    "        break\n",
    "    return tif_file_map\n",
    "\n",
    "def flat_dict_to_nested(flat: dict, key_delim: str = \".\") -> dict:\n",
    "    \"\"\"\n",
    "    Utility method to convert a flat dictionary into a nested dictionary.\n",
    "    Modified from https://stackoverflow.com/a/50607551\n",
    "    Parameters\n",
    "    ----------\n",
    "    flat : dict\n",
    "      Example {\"a.b.c\": 1, \"a.b.d\": 2, \"e.f\": 3}\n",
    "    key_delim : str\n",
    "      Delimiter on dictionary keys. Default is '.'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "      A nested dictionary like {\"a\": {\"b\": {\"c\":1, \"d\":2}, \"e\": {\"f\":3}}\n",
    "    \"\"\"\n",
    "\n",
    "    def __nest_dict_rec(k, v, out) -> None:\n",
    "        \"\"\"Simple recursive method being called.\"\"\"\n",
    "        k, *rest = k.split(key_delim, 1)\n",
    "        if rest:\n",
    "            __nest_dict_rec(rest[0], v, out.setdefault(k, {}))\n",
    "        else:\n",
    "            out[k] = v\n",
    "\n",
    "    result = {}\n",
    "    for flat_key, flat_val in flat.items():\n",
    "        __nest_dict_rec(flat_key, flat_val, result)\n",
    "    return result\n",
    "\n",
    "# This methods parses a single file into RawImageInfo dataclass\n",
    "def extract_raw_info_from_file(file_path: Path) -> RawImageInfo:\n",
    "    with ScanImageTiffReader(str(file_path)) as reader:\n",
    "        reader_metadata = reader.metadata()\n",
    "        reader_shape = reader.shape()\n",
    "        reader_descriptions = [\n",
    "            dict(\n",
    "                [\n",
    "                    (s.split(\" = \", 1)[0], s.split(\" = \", 1)[1])\n",
    "                    for s in reader.description(i).strip().split(\"\\n\")\n",
    "                ]\n",
    "            )\n",
    "            for i in range(0, len(reader))\n",
    "        ]\n",
    "\n",
    "    metadata_first_part = reader_metadata.split(\"\\n\\n\")[0]\n",
    "    flat_metadata_header_dict = dict(\n",
    "        [\n",
    "            (s.split(\" = \", 1)[0], s.split(\" = \", 1)[1])\n",
    "            for s in metadata_first_part.split(\"\\n\")\n",
    "        ]\n",
    "    )\n",
    "    metadata_dict = flat_dict_to_nested(flat_metadata_header_dict)\n",
    "    reader_metadata_json = json.loads(reader_metadata.split(\"\\n\\n\")[1])\n",
    "    # Move SI dictionary up one level\n",
    "    if \"SI\" in metadata_dict.keys():\n",
    "        si_contents = metadata_dict.pop(\"SI\")\n",
    "        metadata_dict.update(si_contents)\n",
    "    return RawImageInfo(\n",
    "        reader_shape=reader_shape,\n",
    "        reader_metadata_header=metadata_dict,\n",
    "        reader_metadata_json=reader_metadata_json,\n",
    "        reader_descriptions=reader_descriptions,\n",
    "    )\n",
    "# vvvvvvvvvvvv MARTON HAS REMOVED THIS FUNCTION AS IT GENERATED NEW CONVENTIONS THAT MAKE IT HARDER TO FOLLOW vvvvvvvvvvvvvv\n",
    "\n",
    "# This method transforms a RawImageInfo class into an intermediate ParsedMetadatInfo class.\n",
    "# It should be easier to deal with the more focused ParsedMetadataInfo class than the RawImageInfo.\n",
    "# If other fields from the RawImageInfo are needed downstream, we can update things here.\n",
    "\n",
    "# def parse_raw_metadata(\n",
    "#     raw_image_info: RawImageInfo, number_of_files: int\n",
    "# ) -> ParsedMetadataInfo:\n",
    "#     h_roi_manager = raw_image_info.reader_metadata_header.get(\n",
    "#         \"hRoiManager\", {}\n",
    "#     )\n",
    "#     h_beams = raw_image_info.reader_metadata_header.get(\"hBeams\", {})\n",
    "#     h_fast_z = raw_image_info.reader_metadata_header.get(\"hFastZ\", {})\n",
    "#     h_photostim = raw_image_info.reader_metadata_header.get(\n",
    "#         \"hPhotostim\", {}\n",
    "#     )\n",
    "#     roi_groups = raw_image_info.reader_metadata_json.get(\"RoiGroups\", {})\n",
    "#     imaging_roi_group = roi_groups.get(\"imagingRoiGroup\", {})\n",
    "#     photostim_roi_groups = roi_groups.get(\"photostimRoiGroups\", [])\n",
    "\n",
    "#     reader_description_last = raw_image_info.reader_descriptions[-1]\n",
    "\n",
    "#     tif_file_group = map_raw_image_info_to_tif_file_group(\n",
    "#         raw_image_info=raw_image_info\n",
    "#     )\n",
    "\n",
    "#     return ParsedMetadataInfo(\n",
    "#         tif_file_group=tif_file_group,\n",
    "#         number_of_tif_files=number_of_files,\n",
    "#         h_photostim=h_photostim,\n",
    "#         h_roi_manager=h_roi_manager,\n",
    "#         h_beams=h_beams,\n",
    "#         h_fast_z=h_fast_z,\n",
    "#         imaging_roi_group=imaging_roi_group,\n",
    "#         photostim_roi_groups=photostim_roi_groups,\n",
    "#         reader_description_last=reader_description_last,\n",
    "#         reader_shape=raw_image_info.reader_shape,\n",
    "#     )\n",
    "\n",
    "# This method maps a RawImageInfo dataclass into a TifFileGroup type\n",
    "# ^^^^^^^^^MARTON HAS REMOVED THIS FUNCTION AS IT GENERATED NEW CONVENTIONS THAT MAKE IT HARDER TO FOLLOW ^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "\n",
    "def map_raw_image_info_to_tif_file_group(\n",
    "    raw_image_info: RawImageInfo,\n",
    ") -> TifFileGroup:\n",
    "    header = raw_image_info.reader_metadata_header\n",
    "    if header.get(\"hPhotostim\", {}).get(\"status\") in [\n",
    "        \"'Running'\",\n",
    "        \"Running\",\n",
    "    ]:\n",
    "        return TifFileGroup.PHOTOSTIM\n",
    "    elif (\n",
    "        header.get(\"hIntegrationRoiManager\", {}).get(\"enable\") == \"true\"\n",
    "        and header.get(\"hIntegrationRoiManager\", {}).get(\n",
    "            \"outputChannelsEnabled\"\n",
    "        )\n",
    "        == \"true\"\n",
    "        and header.get(\"extTrigEnable\", {}) == \"1\"\n",
    "    ):\n",
    "        return TifFileGroup.BEHAVIOR\n",
    "    elif header.get(\"hStackManager\", {}).get(\"enable\") == \"true\":\n",
    "        return TifFileGroup.STACK\n",
    "    else:\n",
    "        return TifFileGroup.SPONTANEOUS\n",
    "# Loops through tif file locations and transforms them into a dictionary of ParsedMetadataInfo\n",
    "\n",
    "def extract_parsed_metadata_info_from_files(\n",
    "    tif_file_locations: Dict[str, List[Path]]\n",
    ") -> Dict[Tuple[str, TifFileGroup], ParsedMetadataInfo]:\n",
    "    parsed_map = {}\n",
    "    for file_stem, files in tif_file_locations.items():\n",
    "        number_of_files = len(files)\n",
    "        last_file = files[-1]\n",
    "        raw_info = extract_raw_info_from_file(last_file)\n",
    "        raw_info_first_file = extract_raw_info_from_file(files[0])\n",
    "        # parsed_info = parse_raw_metadata(\n",
    "        #     raw_image_info=raw_info, number_of_files=number_of_files\n",
    "        # )\n",
    "        tif_file_group = map_raw_image_info_to_tif_file_group(\n",
    "        raw_image_info=raw_info\n",
    "    )\n",
    "        parsed_map[(file_stem, tif_file_group)] = [raw_info,[files],raw_info_first_file]\n",
    "    return parsed_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7709665b-5c02-453d-8724-c8e80ecf2c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tif_file_path = Path(\"/home/jupyter/bucket/Data/Calcium_imaging/raw/Bergamo-2P-Photostim/BCI_29/052422\")\n",
    "job_settings = JobSettings(input_source=tif_file_path,\n",
    "                           experimenter_full_name=[\"John Apple\"],\n",
    "                           subject_id=\"061022\",\n",
    "                           imaging_laser_wavelength = 920, #nm\n",
    "                           fov_imaging_depth  =200, #microns\n",
    "                           fov_targeted_structure = 'Primary Motor Cortex',\n",
    "                           notes = 'test upload'\n",
    "                          )\n",
    "#separate files by basenames\n",
    "tif_file_locations = get_tif_file_locations(job_settings=job_settings)\n",
    "#parse metadata\n",
    "parsed_metadata = extract_parsed_metadata_info_from_files(tif_file_locations=tif_file_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "089e7d9e-b0fe-4d09-ac1d-637ebe1f5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_file_info = [\n",
    "    (k, v)\n",
    "    for k, v in parsed_metadata.items()\n",
    "    if k[1] == TifFileGroup.STACK\n",
    "]\n",
    "spont_file_info = [\n",
    "    (k, v)\n",
    "    for k, v in parsed_metadata.items()\n",
    "    if k[1] == TifFileGroup.SPONTANEOUS\n",
    "]\n",
    "behavior_file_info = [\n",
    "    (k, v)\n",
    "    for k, v in parsed_metadata.items()\n",
    "    if k[1] == TifFileGroup.BEHAVIOR\n",
    "]\n",
    "photo_stim_file_info = [\n",
    "    (k, v)\n",
    "    for k, v in parsed_metadata.items()\n",
    "    if k[1] == TifFileGroup.PHOTOSTIM\n",
    "]\n",
    "first_tiff_metadata_header = parsed_metadata[list(parsed_metadata.keys())[0]][0].reader_metadata_header # to get scanimage version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "655bbc84-0529-4bda-b44e-6ed0beacb71a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# here key is channel in scanimage\n",
    "channel_dict = {1:{'channel_name':'Ch1', \n",
    "                   'light_source_name' : job_settings.imaging_laser_name,\n",
    "                   'filter_names' : [], # FROM RIG JSON\n",
    "                   'detector_name': '',# FROM RIG JSON\n",
    "                   'excitation_wavelength':job_settings.imaging_laser_wavelength,\n",
    "                   'daq_name':'',# FROM RIG JSON\n",
    "                  },\n",
    "               2:{'channel_name':'Ch2',\n",
    "                   'light_source_name' : job_settings.imaging_laser_name,\n",
    "                   'filter_names' : [], # FROM RIG JSON\n",
    "                   'detector_name': '',# FROM RIG JSON\n",
    "                  'excitation_wavelength':job_settings.imaging_laser_wavelength,\n",
    "                  'daq_name':'',# FROM RIG JSON\n",
    "                  }}\n",
    "laser_dict = {'imaging_laser':{'power_index':0},\n",
    "             'photostim_laser':{'power_index':1}}\n",
    "FOV_1x_micron = 1000\n",
    "\n",
    "\n",
    "\n",
    "lickportposition = RelativePosition(device_position_transformations = [Translation3dTransform(translation = job_settings.starting_lickport_position), # this is the standard position for BCI task\n",
    "                                                                      Rotation3dTransform(rotation = [0]*9)], # this is the standard position for BCI task\n",
    "                                    device_origin = 'tip of the lickspout',\n",
    "                                    device_axes = [Axis(name = AxisName.X,direction = 'lateral motion'),\n",
    "                                                  Axis(name = AxisName.Y,direction = 'rostro-caudal motion positive is towards mouse, negative is away'),\n",
    "                                                  Axis(name = AxisName.Z,direction = 'up/down')] )\n",
    "\n",
    "reward_spout_config = RewardSpoutConfig(side=SpoutSide.CENTER,\n",
    "                                        starting_position = lickportposition,\n",
    "                                        variable_position = True,\n",
    "                                       )\n",
    "reward_delivery = RewardDeliveryConfig(reward_solution = RewardSolution.WATER,\n",
    "                                      reward_spouts = [reward_spout_config])\n",
    "behavior_software = Software(name = 'pyBpod',\n",
    "                             version = '1.8.2',#hard coded\n",
    "                             url = 'https://github.com/pybpod/pybpod') \n",
    "pybpod_script = Software(name = 'pybpod_basic.py',#file name\n",
    "                         version = '1',#commit#\n",
    "                         url = 'https://github.com/rozmar/BCI-motor-control/blob/main/BCI-pybpod-protocols/bci_basic.py',\n",
    "                         parameters = {}) #  can I do this?\n",
    "photostim_software  = Software(name = 'ScanImage',\n",
    "                            version = '{}.{}.{}'.format(first_tiff_metadata_header['VERSION_MAJOR'],\n",
    "                                                        first_tiff_metadata_header['VERSION_MINOR'],\n",
    "                                                        first_tiff_metadata_header['VERSION_UPDATE']),#hard coded\n",
    "                            url = 'https://www.mbfbioscience.com/products/scanimage/') #hard coded\n",
    "\n",
    "all_stream_start_times = []\n",
    "all_stream_end_times = []\n",
    "streams = []\n",
    "stim_epochs = []\n",
    "for stack_file_info_now in stack_file_info: # ONLY 2P STREAM DURING STACKS\n",
    "    tiff_header = stack_file_info_now[1][0].reader_metadata_header\n",
    "    last_frame_description = stack_file_info_now[1][0].reader_descriptions[-1]\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################\n",
    "    z_list = np.asarray(tiff_header['hStackManager']['zs'].strip('[]').split(' '),float)\n",
    "    z_start = np.min(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_end = np.max(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_step = float(tiff_header['hStackManager']['stackZStepSize'])\n",
    "    channel_nums = np.asarray(tiff_header['hChannels']['channelSave'].strip('[]').split(' ') ,int)\n",
    "    daq_names = []\n",
    "    for channel_num in channel_nums: daq_names.append(channel_dict[channel_num]['daq_name'])\n",
    "    channels = []\n",
    "    start_time_corrected = last_frame_description['epoch'].strip('[]').replace('  ',' 0').split(' ')\n",
    "    start_time_corrected = ' '.join(start_time_corrected[:-1] + [str(int(np.floor(float(start_time_corrected[-1])))).zfill(2),str(int(1000000*(float(start_time_corrected[-1])%1))).zfill(6)])\n",
    "    stream_start_time = datetime.strptime(start_time_corrected,'%Y %m %d %H %M %S %f').replace(tzinfo=job_settings.timezone) \n",
    "    stream_start_time = stream_start_time.replace(tzinfo=job_settings.timezone)\n",
    "    stream_end_time = stream_start_time+timedelta(seconds = float(last_frame_description['frameTimestamps_sec']))\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################\n",
    "    all_stream_start_times.append(stream_start_time)\n",
    "    all_stream_end_times.append(stream_end_time)\n",
    "    for channel_num in channel_nums:\n",
    "        channels.append(StackChannel(start_depth = z_start,\n",
    "                                    end_depth = z_end, \n",
    "                                    channel_name = channel_dict[channel_num]['channel_name'], \n",
    "                                    light_source_name = channel_dict[channel_num]['light_source_name'],\n",
    "                                    filter_names = channel_dict[channel_num]['filter_names'],\n",
    "                                    detector_name = channel_dict[channel_num]['detector_name'],\n",
    "                                    excitation_wavelength = channel_dict[channel_num]['excitation_wavelength'],\n",
    "                                    excitation_power = np.asarray(tiff_header['hBeams']['powers'].strip('[]').split(' '),float)[laser_dict['imaging_laser']['power_index']],# from tiff header,\n",
    "                                    excitation_power_unit = PowerUnit.PERCENT,\n",
    "                                    filter_wheel_index = 0))\n",
    "    zstack = Stack(channels = channels,\n",
    "                  number_of_planes = int(tiff_header['hStackManager']['numSlices']),\n",
    "                  step_size = z_step,\n",
    "                  number_of_plane_repeats_per_volume = int(tiff_header['hStackManager']['framesPerSlice']),\n",
    "                  number_of_volume_repeats = int(tiff_header['hStackManager']['numVolumes']),\n",
    "                  fov_coordinate_ml = job_settings.fov_coordinate_ml,\n",
    "                  fov_coordinate_ap = job_settings.fov_coordinate_ap,\n",
    "                  fov_reference = 'there is no reference',\n",
    "                  fov_width = int(tiff_header['hRoiManager']['pixelsPerLine']),\n",
    "                  fov_height = int(tiff_header['hRoiManager']['linesPerFrame']),\n",
    "                  magnification = str(tiff_header['hRoiManager']['scanZoomFactor']),\n",
    "                  fov_scale_factor = (FOV_1x_micron/float(tiff_header['hRoiManager']['scanZoomFactor']))/float(tiff_header['hRoiManager']['linesPerFrame']), #microns per pixel\n",
    "                  frame_rate = float(tiff_header['hRoiManager']['scanFrameRate']),\n",
    "                  targeted_structure = job_settings.fov_targeted_structure, \n",
    "                  )\n",
    "    stream_stack = Stream(stream_start_time = stream_start_time,\n",
    "                       stream_end_time = stream_end_time,\n",
    "                       daq_names = daq_names,\n",
    "                       light_sources = [LaserConfig(name = job_settings.imaging_laser_name,#from rig json\n",
    "                                                    wavelength = job_settings.imaging_laser_wavelength,# user set value\n",
    "                                                    excitation_power = np.asarray(tiff_header['hBeams']['powers'].strip('[]').split(' '),float)[laser_dict['imaging_laser']['power_index']],\n",
    "                                                    excitation_power_unit = PowerUnit.PERCENT)],\n",
    "                       stack_parameters = zstack,\n",
    "                       stream_modalities = [Modality.POPHYS])\n",
    "    streams.append(stream_stack)\n",
    "    \n",
    "for spont_file_info_now in spont_file_info: # ONLY 2P STREAM DURING SPONT\n",
    "    tiff_header = spont_file_info_now[1][0].reader_metadata_header\n",
    "    last_frame_description = spont_file_info_now[1][0].reader_descriptions[-1]\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################\n",
    "    z_list = np.asarray(tiff_header['hStackManager']['zs'].strip('[]').split(' '),float)\n",
    "    z_start = np.min(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_end = np.max(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_step = float(tiff_header['hStackManager']['stackZStepSize'])\n",
    "    channel_nums = np.asarray(tiff_header['hChannels']['channelSave'].strip('[]').split(' ') ,int)\n",
    "    daq_names = []\n",
    "    for channel_num in channel_nums: daq_names.append(channel_dict[channel_num]['daq_name'])\n",
    "    channels = []\n",
    "    start_time_corrected = last_frame_description['epoch'].strip('[]').replace('  ',' 0').split(' ')\n",
    "    start_time_corrected = ' '.join(start_time_corrected[:-1] + [str(int(np.floor(float(start_time_corrected[-1])))).zfill(2),str(int(1000000*(float(start_time_corrected[-1])%1))).zfill(6)])\n",
    "    stream_start_time = datetime.strptime(start_time_corrected,'%Y %m %d %H %M %S %f') \n",
    "    stream_start_time = stream_start_time.replace(tzinfo=job_settings.timezone)\n",
    "    stream_end_time = stream_start_time+timedelta(seconds = float(last_frame_description['frameTimestamps_sec']))\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################\n",
    "    all_stream_start_times.append(stream_start_time)\n",
    "    all_stream_end_times.append(stream_end_time)\n",
    "    fov_2p = FieldOfView(index = 0,# multi-plane will have multiple - in a list\n",
    "                         imaging_depth = job_settings.fov_imaging_depth, # in microns\n",
    "                         fov_coordinate_ml = job_settings.fov_coordinate_ml,\n",
    "                         fov_coordinate_ap = job_settings.fov_coordinate_ap,\n",
    "                         fov_reference = 'there is no reference',\n",
    "                         fov_width = int(tiff_header['hRoiManager']['pixelsPerLine']),\n",
    "                         fov_height = int(tiff_header['hRoiManager']['linesPerFrame']),\n",
    "                         magnification = str(tiff_header['hRoiManager']['scanZoomFactor']),\n",
    "                         fov_scale_factor = (FOV_1x_micron/float(tiff_header['hRoiManager']['scanZoomFactor']))/float(tiff_header['hRoiManager']['linesPerFrame']), #microns per pixel\n",
    "                         frame_rate = float(tiff_header['hRoiManager']['scanFrameRate']),\n",
    "                         targeted_structure = job_settings.fov_targeted_structure, \n",
    "                        )\n",
    "    stream_2p = Stream(stream_start_time = stream_start_time,#calculate - specify timezone # each basename is a separate stream\n",
    "                       stream_end_time = stream_end_time,#calculate\n",
    "                       daq_names = daq_names,# from the rig json\n",
    "                       light_sources = [LaserConfig(name = job_settings.imaging_laser_name,#from rig json\n",
    "                                                    wavelength = job_settings.imaging_laser_wavelength,# user set value\n",
    "                                                    excitation_power = np.asarray(tiff_header['hBeams']['powers'].strip('[]').split(' '),float)[laser_dict['imaging_laser']['power_index']],# from tiff header,\n",
    "                                                    excitation_power_unit = PowerUnit.PERCENT)],\n",
    "                       ophys_fovs = [fov_2p], # multiple planes come here\n",
    "                       stream_modalities = [Modality.POPHYS],\n",
    "                      )\n",
    "    streams.append(stream_2p)\n",
    "    \n",
    "    \n",
    "    stim_epoch_spont = StimulusEpoch(stimulus_start_time = stream_start_time,#datetime#basenames are separate\n",
    "                                   stimulus_end_time = stream_end_time,#datetime, \n",
    "                                   stimulus_name = 'spontaneous activity',# user defined in script\n",
    "                                   stimulus_modalities = [StimulusModality.NONE],\n",
    "                                   notes = 'absence of any kind of stimulus')\n",
    "    stim_epochs.append(stim_epoch_spont)\n",
    "\n",
    "\n",
    "    \n",
    "for behavior_file_info_now in behavior_file_info: #  2P + behavior + behavior video STREAM DURING BEHAVIOR\n",
    "    tiff_header = behavior_file_info_now[1][0].reader_metadata_header\n",
    "    last_frame_description = behavior_file_info_now[1][0].reader_descriptions[-1]\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################\n",
    "    \n",
    "    z_list = np.asarray(tiff_header['hStackManager']['zs'].strip('[]').split(' '),float)\n",
    "    z_start = np.min(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_end = np.max(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_step = float(tiff_header['hStackManager']['stackZStepSize'])\n",
    "    channel_nums = np.asarray(tiff_header['hChannels']['channelSave'].strip('[]').split(' ') ,int)\n",
    "    daq_names = []\n",
    "    for channel_num in channel_nums: daq_names.append(channel_dict[channel_num]['daq_name'])\n",
    "    channels = []\n",
    "    start_time_corrected = last_frame_description['epoch'].strip('[]').replace('  ',' 0').split(' ')\n",
    "    start_time_corrected = ' '.join(start_time_corrected[:-1] + [str(int(np.floor(float(start_time_corrected[-1])))).zfill(2),str(int(1000000*(float(start_time_corrected[-1])%1))).zfill(6)])\n",
    "    stream_start_time = datetime.strptime(start_time_corrected,'%Y %m %d %H %M %S %f')\n",
    "    stream_start_time = stream_start_time.replace(tzinfo=job_settings.timezone)\n",
    "    stream_end_time = stream_start_time+timedelta(seconds = float(last_frame_description['frameTimestamps_sec']))\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################   \n",
    "    all_stream_start_times.append(stream_start_time)\n",
    "    all_stream_end_times.append(stream_end_time)\n",
    "    fov_2p = FieldOfView(index = 0,# multi-plane will have multiple - in a list\n",
    "                         imaging_depth = job_settings.fov_imaging_depth, # in microns\n",
    "                         fov_coordinate_ml = job_settings.fov_coordinate_ml,\n",
    "                         fov_coordinate_ap = job_settings.fov_coordinate_ap,\n",
    "                         fov_reference = 'there is no reference',\n",
    "                         fov_width = int(tiff_header['hRoiManager']['pixelsPerLine']),\n",
    "                         fov_height = int(tiff_header['hRoiManager']['linesPerFrame']),\n",
    "                         magnification = str(tiff_header['hRoiManager']['scanZoomFactor']),\n",
    "                         fov_scale_factor = (FOV_1x_micron/float(tiff_header['hRoiManager']['scanZoomFactor']))/float(tiff_header['hRoiManager']['linesPerFrame']), #microns per pixel\n",
    "                         frame_rate = float(tiff_header['hRoiManager']['scanFrameRate']),\n",
    "                         targeted_structure = job_settings.fov_targeted_structure, \n",
    "                        )\n",
    "    stream_2p = Stream(stream_start_time = stream_start_time,#calculate - specify timezone # each basename is a separate stream\n",
    "                       stream_end_time = stream_end_time,#calculate\n",
    "                       daq_names = daq_names,# from the rig json\n",
    "                       light_sources = [LaserConfig(name = job_settings.imaging_laser_name,#from rig json\n",
    "                                                    wavelength = job_settings.imaging_laser_wavelength,# user set value\n",
    "                                                    excitation_power = np.asarray(tiff_header['hBeams']['powers'].strip('[]').split(' '),float)[laser_dict['imaging_laser']['power_index']],# from tiff header,\n",
    "                                                    excitation_power_unit = PowerUnit.PERCENT)],\n",
    "                       ophys_fovs = [fov_2p], # multiple planes come here\n",
    "                       stream_modalities = [Modality.POPHYS,\n",
    "                                           Modality.BEHAVIOR],\n",
    "\n",
    "                      )\n",
    "    streams.append(stream_2p)\n",
    "    if len(job_settings.behavior_camera_names)>0:\n",
    "        stream_facecameras = Stream(stream_start_time = stream_start_time,#calculate - specify timezone\n",
    "                           stream_end_time = stream_end_time,#calculate\n",
    "                           camera_names = job_settings.behavior_camera_names, # from rig json\n",
    "                           stream_modalities = [Modality.BEHAVIOR_VIDEOS])\n",
    "        streams.append(stream_facecameras)\n",
    "\n",
    "    stim_epoch_behavior = StimulusEpoch(stimulus_start_time = stream_start_time,#datetime#basenames are separate\n",
    "                                       stimulus_end_time = stream_end_time,#datetime, \n",
    "                                       stimulus_name = job_settings.behavior_task_name,# user defined in script\n",
    "                                        software = [behavior_software],\n",
    "                                        script = pybpod_script,\n",
    "                                        stimulus_modalities = [StimulusModality.AUDITORY],#,StimulusModality.TACTILE],# tactile not in this version yet\n",
    "                                        stimulus_parameters = [],# opticalBCI class to be added in future\n",
    "                                        stimulus_device_names = [],#from json file, to be added (speaker, bpod ID, )\n",
    "                                        output_parameters = {},#hit rate, time to reward, ...?\n",
    "                                        trials_total = len(behavior_file_info_now[1][1][0]), \n",
    "                                       # trials_rewarded = ,  # not using BPOD info yet\n",
    "                                       )\n",
    "    stim_epochs.append(stim_epoch_behavior)\n",
    "\n",
    "\n",
    "for photo_stim_file_info_now in photo_stim_file_info: #  2P + behavior + behavior video STREAM DURING BEHAVIOR\n",
    "    tiff_header = photo_stim_file_info_now[1][0].reader_metadata_header\n",
    "    last_frame_description = photo_stim_file_info_now[1][0].reader_descriptions[-1]\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################\n",
    "    \n",
    "    z_list = np.asarray(tiff_header['hStackManager']['zs'].strip('[]').split(' '),float)\n",
    "    z_start = np.min(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_end = np.max(z_list)-np.median(z_list) + job_settings.fov_imaging_depth\n",
    "    z_step = float(tiff_header['hStackManager']['stackZStepSize'])\n",
    "    channel_nums = np.asarray(tiff_header['hChannels']['channelSave'].strip('[]').split(' ') ,int)\n",
    "    daq_names = []\n",
    "    for channel_num in channel_nums: daq_names.append(channel_dict[channel_num]['daq_name'])\n",
    "    channels = []\n",
    "    start_time_corrected = last_frame_description['epoch'].strip('[]').replace('  ',' 0').split(' ')\n",
    "    start_time_corrected = ' '.join(start_time_corrected[:-1] + [str(int(np.floor(float(start_time_corrected[-1])))).zfill(2),str(int(1000000*(float(start_time_corrected[-1])%1))).zfill(6)])\n",
    "    stream_start_time = datetime.strptime(start_time_corrected,'%Y %m %d %H %M %S %f')\n",
    "    stream_start_time = stream_start_time.replace(tzinfo=job_settings.timezone)\n",
    "    stream_end_time = stream_start_time+timedelta(seconds = float(last_frame_description['frameTimestamps_sec']))\n",
    "    ###########################################THIS THING REPEATS FOR EVERY STREAM########################################   \n",
    "    all_stream_start_times.append(stream_start_time)\n",
    "    all_stream_end_times.append(stream_end_time)\n",
    "    fov_2p = FieldOfView(index = 0,# multi-plane will have multiple - in a list\n",
    "                         imaging_depth = job_settings.fov_imaging_depth, # in microns\n",
    "                         fov_coordinate_ml = job_settings.fov_coordinate_ml,\n",
    "                         fov_coordinate_ap = job_settings.fov_coordinate_ap,\n",
    "                         fov_reference = 'there is no reference',\n",
    "                         fov_width = int(tiff_header['hRoiManager']['pixelsPerLine']),\n",
    "                         fov_height = int(tiff_header['hRoiManager']['linesPerFrame']),\n",
    "                         magnification = str(tiff_header['hRoiManager']['scanZoomFactor']),\n",
    "                         fov_scale_factor = (FOV_1x_micron/float(tiff_header['hRoiManager']['scanZoomFactor']))/float(tiff_header['hRoiManager']['linesPerFrame']), #microns per pixel\n",
    "                         frame_rate = float(tiff_header['hRoiManager']['scanFrameRate']),\n",
    "                         targeted_structure = job_settings.fov_targeted_structure, \n",
    "                        )\n",
    "    stream_2p = Stream(stream_start_time = stream_start_time,#calculate - specify timezone # each basename is a separate stream\n",
    "                       stream_end_time = stream_end_time,#calculate\n",
    "                       daq_names = daq_names,# from the rig json\n",
    "                       light_sources = [LaserConfig(name = job_settings.imaging_laser_name,#from rig json\n",
    "                                                    wavelength = job_settings.imaging_laser_wavelength,# user set value\n",
    "                                                    excitation_power = np.asarray(tiff_header['hBeams']['powers'].strip('[]').split(' '),float)[laser_dict['imaging_laser']['power_index']],# from tiff header,\n",
    "                                                    excitation_power_unit = PowerUnit.PERCENT)],\n",
    "                       ophys_fovs = [fov_2p], # multiple planes come here\n",
    "                       stream_modalities = [Modality.POPHYS],\n",
    "                      )\n",
    "    streams.append(stream_2p)\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    \n",
    "    photostim_groups = []\n",
    "    group_order = np.asarray(tiff_header['hPhotostim']['sequenceSelectedStimuli'].strip('[]').split(' ')*100,int)-1\n",
    "    num_total_repetitions = len(photo_stim_file_info_now[1][1][0])\n",
    "    group_order = group_order[:num_total_repetitions]\n",
    "    group_powers = []\n",
    "    for photostim_group_i, photostim_group in enumerate(photo_stim_file_info_now[1][0].reader_metadata_json['RoiGroups']['photostimRoiGroups']):\n",
    "        number_of_neurons = int(np.array(photostim_group[\"rois\"][1][\"scanfields\"][\"slmPattern\"]).shape[0])\n",
    "        stimulation_laser_power = Decimal(str(photostim_group[\"rois\"][1][\"scanfields\"][\"powers\"]))\n",
    "        number_spirals = int(photostim_group[\"rois\"][1][\"scanfields\"][\"repetitions\"])\n",
    "        spiral_duration = Decimal(str(photostim_group[\"rois\"][1][\"scanfields\"][\"duration\"]))\n",
    "        inter_spiral_interval = Decimal(str(photostim_group[\"rois\"][2][\"scanfields\"][\"duration\"]+photostim_group[\"rois\"][0][\"scanfields\"][\"duration\"]))\n",
    "\n",
    "        number_of_trials = sum(group_order==photostim_group_i)\n",
    "        photostim_groups.append(PhotoStimulationGroup(\n",
    "                                group_index=photostim_group_i+1,\n",
    "                                number_of_neurons=number_of_neurons,\n",
    "                                stimulation_laser_power=stimulation_laser_power,\n",
    "                                stimulation_laser_power_unit=PowerUnit.PERCENT,\n",
    "                                number_trials=number_of_trials,\n",
    "                                number_spirals=number_spirals,\n",
    "                                spiral_duration=spiral_duration,\n",
    "                                inter_spiral_interval=inter_spiral_interval,\n",
    "                            ))\n",
    "        group_powers.append(stimulation_laser_power)\n",
    "        \n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    photostim = PhotoStimulation(stimulus_name = '2p photostimulation',\n",
    "                                number_groups = len(photostim_groups),#tiff header\n",
    "                                groups = photostim_groups,\n",
    "                                inter_trial_interval = Decimal(float(photo_stim_file_info_now[1][2].reader_descriptions[-1]['nextFileMarkerTimestamps_sec'])))# from Jon's script - seconds\n",
    "      \n",
    "\n",
    "    stim_epoch_photostim = StimulusEpoch(stimulus_start_time = stream_start_time,\n",
    "                                        stimulus_end_time = stream_end_time,#datetime, \n",
    "                                        stimulus_name = '2p photostimulation',# user defined in script\n",
    "                                        software = [photostim_software],\n",
    "                                        stimulus_modalities = [StimulusModality.OPTOGENETICS],\n",
    "                                        stimulus_parameters = [photostim],# opticalBCI class to be added in future\n",
    "                                        stimulus_device_names = [],#from json file, to be added ()\n",
    "                                        light_source_config = LaserConfig(name = job_settings.photostim_laser_name,#from rig json\n",
    "                                                                        wavelength = job_settings.photostim_laser_wavelength,# user set value\n",
    "                                                                        excitation_power = np.nanmean(group_powers),# from tiff header,\n",
    "                                                                        excitation_power_unit = PowerUnit.PERCENT),\n",
    "                                                                           )\n",
    "    stim_epochs.append(stim_epoch_photostim)\n",
    "s =Session(experimenter_full_name = job_settings.experimenter_full_name, #user added\n",
    "           session_start_time = min(all_stream_start_times),\n",
    "           session_end_time = max(all_stream_end_times),\n",
    "           session_type = job_settings.session_type, # user added\n",
    "           iacuc_protocol = job_settings.iacuc_protocol,#user added\n",
    "           rig_id = job_settings.rig_id,#from rig json\n",
    "           # calibrations = [Calibration(calibration_date = ,\n",
    "           #                            device_name = '',#from rig json)\n",
    "           #                             description = 'laser calibration',\n",
    "           #                             input ={'power_percent':[]},\n",
    "           #                             output = {'power_mW':[]})],\n",
    "           subject_id = job_settings.subject_id,#user added\n",
    "           reward_delivery = reward_delivery,\n",
    "           data_streams = streams,\n",
    "           mouse_platform_name = job_settings.mouse_platform_name,#from rig json\n",
    "           active_mouse_platform = job_settings.active_mouse_platform,\n",
    "           stimulus_epochs = stim_epochs,\n",
    "           notes = job_settings.notes,#user added\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "540cf332-65f6-4f2f-afda-33cfa0102031",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized = s.model_dump_json()\n",
    "deserialized = Session.model_validate_json(serialized)\n",
    "deserialized.write_standard_file(prefix=\"ophys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d5329da2-0ec4-4367-a8ff-b740fb01f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/jupyter/temp/session.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(serialized, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "89b4fb2e-ce14-4c28-8ebd-4f309b111824",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.write_standard_file('/home/jupyter/temp/')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "migrate_to_co",
   "name": "common-cpu.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m92"
  },
  "kernelspec": {
   "display_name": "migrate_to_co",
   "language": "python",
   "name": "migrate_to_co"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
